# ğŸ“Š Linear Regression Examples with scikit-learn

This repository demonstrates **Linear Regression** applied to two datasets:
 
* ğŸ¡ **Boston Housing Price Prediction** â€“ predicting housing prices based on neighborhood attributes.

Both projects are implemented using **Python & scikit-learn**, and evaluated with metrics such as **MSE, RMSE, and Cross-Validation scores**.

---

## ğŸ“Œ Key Features

- Handle categorical features using **One-Hot Encoding (dummy variables)**.  
- Train and evaluate **Linear Regression models**.  
- Compute model performance metrics: **MSE** and **RMSE**.  
- Apply **Cross-Validation (CV)** for robust performance measurement.  
- Compare model predictions on **GPA dataset** and **Boston Housing dataset**.  

---

## ğŸ› ï¸ Technologies Used

- Python 3.x  
- NumPy  
- Pandas  
- scikit-learn  

---

## ğŸ“‚ Project Structure

```

ml-linear-regression-examples/
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ Boston.CSV                   # Boston Housing dataset
â”‚   

â”‚â”€â”€ MLO_Feature_Selection_Boston_LinearRegression.py       # Boston housing prediction script
â”‚â”€â”€ requirements.txt                 # Dependencies
â”‚â”€â”€ README.md                        # Project documentation

````

---

## ğŸš€ How to Run

1. Clone this repository:
   ```bash
   git clone https://github.com/vipunsanjana/MLO-ml-feature-selection-rfe.git
   cd MLO-ml-feature-selection-rfe
````

2. Install the dependencies:

   ```bash
   pip install -r requirements.txt
   ```

3. (Optional) Explore the combined Jupyter Notebook:

   ```bash
   jupyter MLO_Feature_Selection_Boston_LinearRegression.ipynb
   ```

---

## ğŸ“ˆ Example Outputs

### ğŸ“ GPA Prediction

* Model intercept & coefficients
* Training **RÂ² score**
* Predictions on test data
* **RMSE** value

### ğŸ¡ Boston Housing Prediction (with CV)

* Fold-wise **RMSE values**
* Average RMSE across folds
* Selected important features (via feature selection methods like RFE/RFECV â€“ optional)

---

## âœ… Future Improvements

* Add **Ridge** and **Lasso Regression** for regularization and comparison.
* Apply **feature scaling** for better performance.
* Add **visualizations** for residuals, errors, and prediction accuracy.
* Extend to **Polynomial Regression** for non-linear patterns.

---

## ğŸ‘¨â€ğŸ’» Author

**Vipun Sanjana**
*Software Engineer | Full Stack | ML & DevOps*

---
